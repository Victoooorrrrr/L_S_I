{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade gensim\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim import similarities\n",
    "from collections import defaultdict\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "with open('stepik_courses.txt', 'r') as s_c, open('coursera_courses.txt', 'r') as c_c, open('openedu_courses.txt', 'r') as o_c:\n",
    "    documents.extend([line[2:line.find(\", 'https\")-1].strip() for line in s_c])\n",
    "    documents.extend([line[4:line.find(\", 'https\")-3].strip() for line in c_c])\n",
    "    documents.extend(list(map(lambda x: eval(x)[0], [line.strip() for line in o_c])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_info = []\n",
    "with open('stepik_courses.txt', 'r') as s_c, open('coursera_courses.txt', 'r') as c_c, open('openedu_courses.txt', 'r') as o_c:\n",
    "    courses_info.extend([line[1:-2] for line in s_c])\n",
    "    courses_info.extend([line[3:-2] for line in c_c])\n",
    "    courses_info.extend([line[2:-2] for line in o_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stemmer_:\n",
    "    _vowel = \"[аеиоуыэюя]\"\n",
    "    _non_vowel = \"[^аеиоуыэюя]\"\n",
    "\n",
    "    _re_rv = re.compile(_vowel)\n",
    "    _re_r1 = re.compile(_vowel + _non_vowel)\n",
    "\n",
    "    _re_perfective_gerund = re.compile(\n",
    "        r\"(((?P<ignore>[ая])(в|вши|вшись))|(ив|ивши|ившись|ыв|ывши|ывшись))$\"\n",
    "    )\n",
    "    _re_adjective = re.compile(\n",
    "        r\"(ее|ие|ые|ое|ими|ыми|ей|ий|ый|ой|ем|им|ым|ом|его|ого|ему|ому|их|ых|\"\n",
    "        r\"ую|юю|ая|яя|ою|ею)$\"\n",
    "    )\n",
    "    _re_participle = re.compile(\n",
    "        r\"(((?P<ignore>[ая])(ем|нн|вш|ющ|щ))|(ивш|ывш|ующ))$\"\n",
    "    )\n",
    "    _re_reflexive = re.compile(\n",
    "        r\"(ся|сь)$\"\n",
    "    )\n",
    "    _re_verb = re.compile(\n",
    "        r\"(((?P<ignore>[ая])(ла|на|ете|йте|ли|й|л|ем|н|ло|но|ет|ют|ны|ть|ешь|\"\n",
    "        r\"нно))|(ила|ыла|ена|ейте|уйте|ите|или|ыли|ей|уй|ил|ыл|им|ым|ен|ило|\"\n",
    "        r\"ыло|ено|ят|ует|уют|ит|ыт|ены|ить|ыть|ишь|ую|ю))$\"\n",
    "    )\n",
    "    _re_noun = re.compile(\n",
    "        r\"(а|ев|ов|ие|ье|е|иями|ями|ами|еи|ии|и|ией|ей|ой|ий|й|иям|ям|ием|ем|\"\n",
    "        r\"ам|ом|о|у|ах|иях|ях|ы|ь|ию|ью|ю|ия|ья|я)$\"\n",
    "    )\n",
    "    _re_superlative = re.compile(\n",
    "        r\"(ейш|ейше)$\"\n",
    "    )\n",
    "    _re_derivational = re.compile(\n",
    "        r\"(ост|ость)$\"\n",
    "    )\n",
    "    _re_i = re.compile(\n",
    "        r\"и$\"\n",
    "    )\n",
    "    _re_nn = re.compile(\n",
    "        r\"((?<=н)н)$\"\n",
    "    )\n",
    "    _re_ = re.compile(\n",
    "        r\"ь$\"\n",
    "    )\n",
    "\n",
    "    def stem(self, word):\n",
    "        \"\"\"\n",
    "        Gets the stem.\n",
    "        \"\"\"\n",
    "\n",
    "        rv_pos, r2_pos = self._find_rv(word), self._find_r2(word)\n",
    "        word = self._step_1(word, rv_pos)\n",
    "        word = self._step_2(word, rv_pos)\n",
    "        word = self._step_3(word, r2_pos)\n",
    "        word = self._step_4(word, rv_pos)\n",
    "        return word\n",
    "\n",
    "    def _find_rv(self, word):\n",
    "        \n",
    "        rv_match = self._re_rv.search(word)\n",
    "        if not rv_match:\n",
    "            return len(word)\n",
    "        return rv_match.end()\n",
    "\n",
    "    def _find_r2(self, word):\n",
    "\n",
    "        r1_match = self._re_r1.search(word)\n",
    "        if not r1_match:\n",
    "            return len(word)\n",
    "        r2_match = self._re_r1.search(word, r1_match.end())\n",
    "        if not r2_match:\n",
    "            return len(word)\n",
    "        return r2_match.end()\n",
    "\n",
    "    def _cut(self, word, ending, pos):\n",
    "\n",
    "        match = ending.search(word, pos)\n",
    "        if match:\n",
    "            try:\n",
    "                ignore = match.group(\"ignore\") or \"\"\n",
    "            except IndexError:\n",
    "                # No ignored characters in pattern.\n",
    "                return True, word[:match.start()]\n",
    "            else:\n",
    "                # Do not cut ignored part.\n",
    "                return True, word[:match.start() + len(ignore)]\n",
    "        else:\n",
    "            return False, word\n",
    "\n",
    "    def _step_1(self, word, rv_pos):\n",
    "        match, word = self._cut(word, self._re_perfective_gerund, rv_pos)\n",
    "        if match:\n",
    "            return word\n",
    "        _, word = self._cut(word, self._re_reflexive, rv_pos)\n",
    "        match, word = self._cut(word, self._re_adjective, rv_pos)\n",
    "        if match:\n",
    "            _, word = self._cut(word, self._re_participle, rv_pos)\n",
    "            return word\n",
    "        match, word = self._cut(word, self._re_verb, rv_pos)\n",
    "        if match:\n",
    "            return word\n",
    "        _, word = self._cut(word, self._re_noun, rv_pos)\n",
    "        return word\n",
    "\n",
    "    def _step_2(self, word, rv_pos):\n",
    "        _, word = self._cut(word, self._re_i, rv_pos)\n",
    "        return word\n",
    "\n",
    "    def _step_3(self, word, r2_pos):\n",
    "        _, word = self._cut(word, self._re_derivational, r2_pos)\n",
    "        return word\n",
    "\n",
    "    def _step_4(self, word, rv_pos):\n",
    "        _, word = self._cut(word, self._re_superlative, rv_pos)\n",
    "        match, word = self._cut(word, self._re_nn, rv_pos)\n",
    "        if not match:\n",
    "            _, word = self._cut(word, self._re_, rv_pos)\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = Stemmer_()\n",
    "stoplist = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    [stemmer.stem(word) for word in document.lower().split() if word not in stoplist]\n",
    "    for document in documents\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = models.TfidfModel(corpus)\n",
    "corpus_= tf_idf[corpus]\n",
    "lsi = models.LsiModel(corpus_, id2word=dictionary, num_topics = 500) #<========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = similarities.MatrixSimilarity(lsi[corpus_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(query, dic = dictionary, stemmer = stemmer, model = lsi, index = index):\n",
    "    q_bow = dictionary.doc2bow(list(map(stemmer.stem, query.lower().split())))\n",
    "    q_lsi = model[q_bow]\n",
    "    sims = index[q_lsi]\n",
    "    print(f'query: {query}\\n') \n",
    "    sims = sorted(enumerate(sims), key = lambda item: -item[1])[:10]\n",
    "    for doc_position, doc_score in sims:\n",
    "        print(doc_score, courses_info[doc_position])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: Теория вероятностей матстатистика\n",
      "\n",
      "0.98615897 'Теория вероятностей', 'https://stepik.org/course/98940/promo'\n",
      "0.98615897 'Теория вероятностей', 'https://stepik.org/course/94188/promo'\n",
      "0.98615897 'Теория вероятности', 'https://stepik.org/course/52970/promo'\n",
      "0.98615897 'Теория вероятностей', 'https://stepik.org/course/3089/promo'\n",
      "0.98615897 'Теория вероятностей', 'https://stepik.org/course/3066/promo'\n",
      "0.98615897 Теория вероятностей', 'СПбГЭТУ «ЛЭТИ»', '/course/eltech/probability_theory/'\n",
      "0.86690706 Введение в теорию вероятностей', 'МФТИ', '/course/mipt/PROBTH/'\n",
      "0.8237488 'Теория вероятностей для начинающих''', 'https://www.coursera.org/learn/probability-theory-basics, '''Moscow Institute of Physics and Technology'''\n",
      "0.8004688 'Теория вероятностей и ее приложения''', 'https://www.coursera.org/learn/prob-theory, '''HSE University'''\n",
      "0.79300666 'Теория вероятностей - II (дискретные случайные процессы)', 'https://stepik.org/course/57281/promo'\n"
     ]
    }
   ],
   "source": [
    "query('Теория вероятностей матстатистика')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
